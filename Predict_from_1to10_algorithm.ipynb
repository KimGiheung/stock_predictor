{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Predict_from_1to10_algorithm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLOajHzL7CW/NwnGaEBE9M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1에서 10까지 예측 모델 구하기\n","<hr>\n","- 목표 : 1을 넣게되면 1이 출력되고, 2를 넣게되면 2가 출력 되는, 입력값을 그대로<br> 출력해주는 딥러닝 예측 모델을 구현할 것이다.<br>\n","- 딥러닝 이론<br>\n","딥러닝은 어렵게 느쎠지지만, 1차 함수의 가장 기본 단위인 \n","\n","> $$y=ax + b$$\n","\n","형태로 모든 것이 해결된다. 딥러닝에서는 위 수식을 아래와 같이 약간 다르게 표현한다.<br>\n","\n","> $$h(x) = wx + b$$\n","\n","a만 w로 바꿨다 수학에서는 기울기라고 불리지만, 딥러닝에서는 이를 입력값 x에 곱해지는<br>\n","값이라하여 weight, 또는 가중치라고 한다.b는 기본적으로 있는 상수로 'bias'라고 한다.<br>\n","h(x)는 'hypothesis'라고 읽고 가설이라고 이해한다.<br>\n","결국 딥러닝은 우리가 빅데이터 등으로 준비한 x값(입력값)과 y값(결과값)을 가지고<br>\n","컴퓨터에 훈련(train)을 시켜서 최적의 w값(weight, 가중치)과 b값(bias, 절편)<br>을 구하는 행위의 반복이다.<br>\n","(※ 이때 컴퓨터는 Cost(비용)이라는 값을 더 제공한다. Cost값은 낮을수록 좋다.※)<br>\n","이후 정확한 값이 예측되었는지 확인하기 위해 'accuracy'와 'predict'를 사용한다.<br>\n","결국, 딥러닝은 1차 함수다."],"metadata":{"id":"yZd4opIGJ_9_"}},{"cell_type":"code","source":["import numpy as np\n","# 데이터 생성\n","x = np.array([1,2,3,4,5,6,7,8,9,10])\n","y = np.array([1,2,3,4,5,6,7,8,9,10])"],"metadata":{"id":"MeSjAtjL_0wG","executionInfo":{"status":"ok","timestamp":1660635973409,"user_tz":-540,"elapsed":3,"user":{"displayName":"김기흥","userId":"07451133083562510396"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# keras 환경 구축\n","from keras.models import Sequential\n","from keras.layers import Dense"],"metadata":{"id":"hm5N_Yn5AH_B","executionInfo":{"status":"ok","timestamp":1660635973961,"user_tz":-540,"elapsed":3,"user":{"displayName":"김기흥","userId":"07451133083562510396"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 딥러닝 회귀 모델 정의\n","model = Sequential()                                                            # 딥러닝 모델을 순차적으로 구성함\n","model.add(Dense(1, input_dim=1))                             # 모델에 Dense layer를 추가함\n","                                                                                # layer 구성\n","                                                                                # 노드 : 1개\n","                                                                                # 입력 형태(dimension): 1차원(scalar값)인 값 형태(1, 2, 4 이런 값들을 의미)\n","                                                                                # 활성화합수 : relu                                                                        "],"metadata":{"id":"WKJRd-BxF9zU","executionInfo":{"status":"ok","timestamp":1660635973961,"user_tz":-540,"elapsed":3,"user":{"displayName":"김기흥","userId":"07451133083562510396"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 우리의 코드를 머신이 이해할 수 있도록 하는 컴파일 작업\n","model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse']) # loss: 손실 함수는 평균제곱오차(mean_squared_error)\n","# model training\n","model.fit(x, y, epochs=100, batch_size = 1)\n","# measure\n","loss, acc = model.evaluate(x, y, batch_size = 1)\n","\n","print(\"loss : \",loss)\n","print(\"acc : \",acc)"],"metadata":{"id":"4o3Y0xgrHJHn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660635977662,"user_tz":-540,"elapsed":3704,"user":{"displayName":"김기흥","userId":"07451133083562510396"}},"outputId":"2a31a0ce-4076-43e6-eab0-43e278ce40d4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 0s 2ms/step - loss: 1.5905 - mse: 1.5905\n","Epoch 2/100\n","10/10 [==============================] - 0s 2ms/step - loss: 1.4440 - mse: 1.4440\n","Epoch 3/100\n","10/10 [==============================] - 0s 2ms/step - loss: 1.3316 - mse: 1.3316\n","Epoch 4/100\n","10/10 [==============================] - 0s 3ms/step - loss: 1.2090 - mse: 1.2090\n","Epoch 5/100\n","10/10 [==============================] - 0s 3ms/step - loss: 1.0811 - mse: 1.0811\n","Epoch 6/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9912 - mse: 0.9912\n","Epoch 7/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.9000 - mse: 0.9000\n","Epoch 8/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.8072 - mse: 0.8072\n","Epoch 9/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.7227 - mse: 0.7227\n","Epoch 10/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.6411 - mse: 0.6411\n","Epoch 11/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.5841 - mse: 0.5841\n","Epoch 12/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.5188 - mse: 0.5188\n","Epoch 13/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.4575 - mse: 0.4575\n","Epoch 14/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.4169 - mse: 0.4169\n","Epoch 15/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3577 - mse: 0.3577\n","Epoch 16/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.3161 - mse: 0.3161    \n","Epoch 17/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.2864 - mse: 0.2864\n","Epoch 18/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2455 - mse: 0.2455\n","Epoch 19/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.2182 - mse: 0.2182\n","Epoch 20/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.1923 - mse: 0.1923\n","Epoch 21/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.1675 - mse: 0.1675\n","Epoch 22/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.1429 - mse: 0.1429\n","Epoch 23/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.1265 - mse: 0.1265\n","Epoch 24/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.1099\n","Epoch 25/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0973 - mse: 0.0973\n","Epoch 26/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0820 - mse: 0.0820\n","Epoch 27/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717\n","Epoch 28/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611\n","Epoch 29/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0539\n","Epoch 30/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470\n","Epoch 31/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0400\n","Epoch 32/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360\n","Epoch 33/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0306\n","Epoch 34/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0269 - mse: 0.0269\n","Epoch 35/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0235 - mse: 0.0235    \n","Epoch 36/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0211\n","Epoch 37/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0191 - mse: 0.0191\n","Epoch 38/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0171 - mse: 0.0171\n","Epoch 39/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0153 - mse: 0.0153\n","Epoch 40/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139\n","Epoch 41/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0126\n","Epoch 42/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0121\n","Epoch 43/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0110 - mse: 0.0110\n","Epoch 44/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0105\n","Epoch 45/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099\n","Epoch 46/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094\n","Epoch 47/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091\n","Epoch 48/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088\n","Epoch 49/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085\n","Epoch 50/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0083    \n","Epoch 51/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0081 - mse: 0.0081\n","Epoch 52/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0079\n","Epoch 53/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0079\n","Epoch 54/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0077 - mse: 0.0077\n","Epoch 55/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076    \n","Epoch 56/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075\n","Epoch 57/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074\n","Epoch 58/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073    \n","Epoch 59/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0072\n","Epoch 60/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0072\n","Epoch 61/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071    \n","Epoch 62/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070\n","Epoch 63/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070\n","Epoch 64/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069    \n","Epoch 65/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0069 - mse: 0.0069\n","Epoch 66/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068\n","Epoch 67/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067\n","Epoch 68/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067\n","Epoch 69/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066\n","Epoch 70/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065    \n","Epoch 71/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065    \n","Epoch 72/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064\n","Epoch 73/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064\n","Epoch 74/100\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0063\n","Epoch 75/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063\n","Epoch 76/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062\n","Epoch 77/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061    \n","Epoch 78/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061    \n","Epoch 79/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061\n","Epoch 80/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060\n","Epoch 81/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059    \n","Epoch 82/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058\n","Epoch 83/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058    \n","Epoch 84/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057\n","Epoch 85/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057\n","Epoch 86/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056    \n","Epoch 87/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056\n","Epoch 88/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055\n","Epoch 89/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055\n","Epoch 90/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054\n","Epoch 91/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053\n","Epoch 92/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053\n","Epoch 93/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052    \n","Epoch 94/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052\n","Epoch 95/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051    \n","Epoch 96/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051\n","Epoch 97/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050\n","Epoch 98/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049\n","Epoch 99/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049    \n","Epoch 100/100\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048\n","loss :  0.004782790783792734\n","acc :  0.004782790783792734\n"]}]}]}