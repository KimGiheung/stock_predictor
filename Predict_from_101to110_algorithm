{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Predict_from_101to110_algorithm","provenance":[{"file_id":"1uqXeLNCOg-XnA2M4X5q5BnmIj3ASkBcN","timestamp":1660631588680}],"collapsed_sections":[],"authorship_tag":"ABX9TyPUYsqf+QA2jtacbYL9qGzz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","# 데이터 생성\n","x_train = np.arange(1, 11)\n","y_train = np.arange(1, 11)\n","x_test  = np.arange(11, 21)\n","y_test  = np.arange(11, 21)\n","x_val   = np.arange(101, 106)\n","y_val   = np.arange(101, 106)\n"],"metadata":{"id":"MeSjAtjL_0wG","executionInfo":{"status":"ok","timestamp":1660638009191,"user_tz":-540,"elapsed":299,"user":{"displayName":"김기흥","userId":"07451133083562510396"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["# 딥러닝 회귀 모델 정의\n","model = Sequential()                                                            # 딥러닝 모델을 순차적으로 구성함\n","model.add(Dense(5, input_shape=(1,), activation = 'relu'))                           # 모델에 Dense layer를 추가함\n","                                                                                # layer 구성\n","                                                                                # 노드 : 1개\n","                                                                                # 입력 형태(dimension): 1차원(scalar값)인 값 형태(1, 2, 4 이런 값들을 의미)\n","                                                                                # 활성화합수 : relu\n","model.add(Dense(3))     \n","model.add(Dense(1, activation = 'relu'))\n","model.summary()                                                                                                                                                                                                                           "],"metadata":{"id":"WKJRd-BxF9zU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660638009552,"user_tz":-540,"elapsed":5,"user":{"displayName":"김기흥","userId":"07451133083562510396"}},"outputId":"4c5150c2-7038-48de-b608-38e863ab4a2a"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_27\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_67 (Dense)            (None, 5)                 10        \n","                                                                 \n"," dense_68 (Dense)            (None, 3)                 18        \n","                                                                 \n"," dense_69 (Dense)            (None, 1)                 4         \n","                                                                 \n","=================================================================\n","Total params: 32\n","Trainable params: 32\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"4o3Y0xgrHJHn","executionInfo":{"status":"ok","timestamp":1660638009868,"user_tz":-540,"elapsed":318,"user":{"displayName":"김기흥","userId":"07451133083562510396"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["# model training\n","model.fit(x_train, y_train, epochs=100, batch_size = 1, validation_data = (x_train, y_train))\n","# measure\n","loss, acc = model.evaluate(x_test, y_test, batch_size = 1)\n","\n","print(\"loss : \",loss)\n","print(\"acc : \",acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7gjXHASYLQa","executionInfo":{"status":"ok","timestamp":1660638020972,"user_tz":-540,"elapsed":11108,"user":{"displayName":"김기흥","userId":"07451133083562510396"}},"outputId":"011096b9-3351-4e83-b12f-329d518c4b7f"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 1s 20ms/step - loss: 34.9424 - accuracy: 0.0000e+00 - val_loss: 33.4971 - val_accuracy: 0.0000e+00\n","Epoch 2/100\n","10/10 [==============================] - 0s 5ms/step - loss: 32.5464 - accuracy: 0.0000e+00 - val_loss: 31.4441 - val_accuracy: 0.0000e+00\n","Epoch 3/100\n","10/10 [==============================] - 0s 6ms/step - loss: 30.6526 - accuracy: 0.0000e+00 - val_loss: 29.3335 - val_accuracy: 0.0000e+00\n","Epoch 4/100\n","10/10 [==============================] - 0s 6ms/step - loss: 28.4073 - accuracy: 0.0000e+00 - val_loss: 27.4911 - val_accuracy: 0.0000e+00\n","Epoch 5/100\n","10/10 [==============================] - 0s 6ms/step - loss: 26.5537 - accuracy: 0.0000e+00 - val_loss: 25.6610 - val_accuracy: 0.0000e+00\n","Epoch 6/100\n","10/10 [==============================] - 0s 7ms/step - loss: 24.8267 - accuracy: 0.0000e+00 - val_loss: 23.8447 - val_accuracy: 0.0000e+00\n","Epoch 7/100\n","10/10 [==============================] - 0s 5ms/step - loss: 23.0311 - accuracy: 0.0000e+00 - val_loss: 22.1831 - val_accuracy: 0.0000e+00\n","Epoch 8/100\n","10/10 [==============================] - 0s 7ms/step - loss: 21.4764 - accuracy: 0.0000e+00 - val_loss: 20.5364 - val_accuracy: 0.1000\n","Epoch 9/100\n","10/10 [==============================] - 0s 5ms/step - loss: 19.9113 - accuracy: 0.1000 - val_loss: 18.9858 - val_accuracy: 0.1000\n","Epoch 10/100\n","10/10 [==============================] - 0s 6ms/step - loss: 18.4589 - accuracy: 0.1000 - val_loss: 17.5056 - val_accuracy: 0.1000\n","Epoch 11/100\n","10/10 [==============================] - 0s 6ms/step - loss: 16.8921 - accuracy: 0.1000 - val_loss: 16.2327 - val_accuracy: 0.1000\n","Epoch 12/100\n","10/10 [==============================] - 0s 7ms/step - loss: 15.6826 - accuracy: 0.1000 - val_loss: 14.9107 - val_accuracy: 0.1000\n","Epoch 13/100\n","10/10 [==============================] - 0s 5ms/step - loss: 14.3620 - accuracy: 0.1000 - val_loss: 13.6939 - val_accuracy: 0.1000\n","Epoch 14/100\n","10/10 [==============================] - 0s 6ms/step - loss: 13.1773 - accuracy: 0.1000 - val_loss: 12.5134 - val_accuracy: 0.1000\n","Epoch 15/100\n","10/10 [==============================] - 0s 5ms/step - loss: 12.0256 - accuracy: 0.1000 - val_loss: 11.4059 - val_accuracy: 0.1000\n","Epoch 16/100\n","10/10 [==============================] - 0s 5ms/step - loss: 10.9806 - accuracy: 0.1000 - val_loss: 10.3185 - val_accuracy: 0.1000\n","Epoch 17/100\n","10/10 [==============================] - 0s 6ms/step - loss: 9.8271 - accuracy: 0.1000 - val_loss: 9.4101 - val_accuracy: 0.1000\n","Epoch 18/100\n","10/10 [==============================] - 0s 6ms/step - loss: 9.0231 - accuracy: 0.1000 - val_loss: 8.3998 - val_accuracy: 0.1000\n","Epoch 19/100\n","10/10 [==============================] - 0s 7ms/step - loss: 8.0159 - accuracy: 0.1000 - val_loss: 7.5297 - val_accuracy: 0.1000\n","Epoch 20/100\n","10/10 [==============================] - 0s 7ms/step - loss: 7.2159 - accuracy: 0.1000 - val_loss: 6.6753 - val_accuracy: 0.1000\n","Epoch 21/100\n","10/10 [==============================] - 0s 5ms/step - loss: 6.3309 - accuracy: 0.1000 - val_loss: 5.9637 - val_accuracy: 0.1000\n","Epoch 22/100\n","10/10 [==============================] - 0s 6ms/step - loss: 5.6057 - accuracy: 0.1000 - val_loss: 5.3028 - val_accuracy: 0.1000\n","Epoch 23/100\n","10/10 [==============================] - 0s 6ms/step - loss: 5.0612 - accuracy: 0.1000 - val_loss: 4.5859 - val_accuracy: 0.1000\n","Epoch 24/100\n","10/10 [==============================] - 0s 6ms/step - loss: 4.4116 - accuracy: 0.1000 - val_loss: 3.9605 - val_accuracy: 0.1000\n","Epoch 25/100\n","10/10 [==============================] - 0s 6ms/step - loss: 3.7817 - accuracy: 0.1000 - val_loss: 3.4456 - val_accuracy: 0.1000\n","Epoch 26/100\n","10/10 [==============================] - 0s 6ms/step - loss: 3.2096 - accuracy: 0.1000 - val_loss: 3.0618 - val_accuracy: 0.1000\n","Epoch 27/100\n","10/10 [==============================] - 0s 7ms/step - loss: 2.8520 - accuracy: 0.1000 - val_loss: 2.6180 - val_accuracy: 0.1000\n","Epoch 28/100\n","10/10 [==============================] - 0s 6ms/step - loss: 2.4545 - accuracy: 0.1000 - val_loss: 2.2226 - val_accuracy: 0.1000\n","Epoch 29/100\n","10/10 [==============================] - 0s 7ms/step - loss: 2.0784 - accuracy: 0.1000 - val_loss: 1.8968 - val_accuracy: 0.1000\n","Epoch 30/100\n","10/10 [==============================] - 0s 6ms/step - loss: 1.7803 - accuracy: 0.1000 - val_loss: 1.6064 - val_accuracy: 0.1000\n","Epoch 31/100\n","10/10 [==============================] - 0s 5ms/step - loss: 1.4991 - accuracy: 0.1000 - val_loss: 1.3722 - val_accuracy: 0.1000\n","Epoch 32/100\n","10/10 [==============================] - 0s 7ms/step - loss: 1.2878 - accuracy: 0.1000 - val_loss: 1.1613 - val_accuracy: 0.1000\n","Epoch 33/100\n","10/10 [==============================] - 0s 6ms/step - loss: 1.0996 - accuracy: 0.1000 - val_loss: 0.9811 - val_accuracy: 0.1000\n","Epoch 34/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.9453 - accuracy: 0.1000 - val_loss: 0.8285 - val_accuracy: 0.1000\n","Epoch 35/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.7827 - accuracy: 0.1000 - val_loss: 0.7250 - val_accuracy: 0.1000\n","Epoch 36/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.6917 - accuracy: 0.1000 - val_loss: 0.6261 - val_accuracy: 0.1000\n","Epoch 37/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.1000 - val_loss: 0.5514 - val_accuracy: 0.1000\n","Epoch 38/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.5222 - accuracy: 0.1000 - val_loss: 0.4918 - val_accuracy: 0.1000\n","Epoch 39/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.1000 - val_loss: 0.4448 - val_accuracy: 0.1000\n","Epoch 40/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.1000 - val_loss: 0.4013 - val_accuracy: 0.1000\n","Epoch 41/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.1000 - val_loss: 0.3664 - val_accuracy: 0.1000\n","Epoch 42/100\n","10/10 [==============================] - 0s 8ms/step - loss: 0.3525 - accuracy: 0.1000 - val_loss: 0.3442 - val_accuracy: 0.1000\n","Epoch 43/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.3393 - accuracy: 0.1000 - val_loss: 0.3203 - val_accuracy: 0.1000\n","Epoch 44/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.3155 - accuracy: 0.1000 - val_loss: 0.3053 - val_accuracy: 0.1000\n","Epoch 45/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.3011 - accuracy: 0.1000 - val_loss: 0.2942 - val_accuracy: 0.1000\n","Epoch 46/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2899 - accuracy: 0.1000 - val_loss: 0.2871 - val_accuracy: 0.1000\n","Epoch 47/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2853 - accuracy: 0.1000 - val_loss: 0.2775 - val_accuracy: 0.1000\n","Epoch 48/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2765 - accuracy: 0.1000 - val_loss: 0.2709 - val_accuracy: 0.1000\n","Epoch 49/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2699 - accuracy: 0.1000 - val_loss: 0.2663 - val_accuracy: 0.1000\n","Epoch 50/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.2652 - accuracy: 0.1000 - val_loss: 0.2625 - val_accuracy: 0.1000\n","Epoch 51/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.2613 - accuracy: 0.1000 - val_loss: 0.2593 - val_accuracy: 0.1000\n","Epoch 52/100\n","10/10 [==============================] - 0s 11ms/step - loss: 0.2578 - accuracy: 0.1000 - val_loss: 0.2563 - val_accuracy: 0.1000\n","Epoch 53/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2548 - accuracy: 0.1000 - val_loss: 0.2534 - val_accuracy: 0.1000\n","Epoch 54/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2523 - accuracy: 0.1000 - val_loss: 0.2504 - val_accuracy: 0.1000\n","Epoch 55/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.1000 - val_loss: 0.2476 - val_accuracy: 0.1000\n","Epoch 56/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2467 - accuracy: 0.1000 - val_loss: 0.2454 - val_accuracy: 0.1000\n","Epoch 57/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2449 - accuracy: 0.1000 - val_loss: 0.2428 - val_accuracy: 0.1000\n","Epoch 58/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2419 - accuracy: 0.1000 - val_loss: 0.2407 - val_accuracy: 0.1000\n","Epoch 59/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2411 - accuracy: 0.1000 - val_loss: 0.2385 - val_accuracy: 0.1000\n","Epoch 60/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.1000 - val_loss: 0.2362 - val_accuracy: 0.1000\n","Epoch 61/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2358 - accuracy: 0.1000 - val_loss: 0.2337 - val_accuracy: 0.1000\n","Epoch 62/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2333 - accuracy: 0.1000 - val_loss: 0.2314 - val_accuracy: 0.1000\n","Epoch 63/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2312 - accuracy: 0.1000 - val_loss: 0.2295 - val_accuracy: 0.1000\n","Epoch 64/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.2293 - accuracy: 0.1000 - val_loss: 0.2272 - val_accuracy: 0.1000\n","Epoch 65/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.1000 - val_loss: 0.2249 - val_accuracy: 0.1000\n","Epoch 66/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.2242 - accuracy: 0.1000 - val_loss: 0.2229 - val_accuracy: 0.1000\n","Epoch 67/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2222 - accuracy: 0.1000 - val_loss: 0.2205 - val_accuracy: 0.1000\n","Epoch 68/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2206 - accuracy: 0.1000 - val_loss: 0.2184 - val_accuracy: 0.1000\n","Epoch 69/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2174 - accuracy: 0.1000 - val_loss: 0.2162 - val_accuracy: 0.1000\n","Epoch 70/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2162 - accuracy: 0.1000 - val_loss: 0.2142 - val_accuracy: 0.1000\n","Epoch 71/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.2136 - accuracy: 0.1000 - val_loss: 0.2117 - val_accuracy: 0.1000\n","Epoch 72/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2112 - accuracy: 0.1000 - val_loss: 0.2096 - val_accuracy: 0.1000\n","Epoch 73/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2095 - accuracy: 0.1000 - val_loss: 0.2072 - val_accuracy: 0.1000\n","Epoch 74/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2065 - accuracy: 0.1000 - val_loss: 0.2051 - val_accuracy: 0.1000\n","Epoch 75/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.1000 - val_loss: 0.2028 - val_accuracy: 0.1000\n","Epoch 76/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 0.1000 - val_loss: 0.2007 - val_accuracy: 0.1000\n","Epoch 77/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.1000 - val_loss: 0.1984 - val_accuracy: 0.1000\n","Epoch 78/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1986 - accuracy: 0.1000 - val_loss: 0.1961 - val_accuracy: 0.1000\n","Epoch 79/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1979 - accuracy: 0.1000 - val_loss: 0.1938 - val_accuracy: 0.1000\n","Epoch 80/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1933 - accuracy: 0.1000 - val_loss: 0.1917 - val_accuracy: 0.1000\n","Epoch 81/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1913 - accuracy: 0.1000 - val_loss: 0.1893 - val_accuracy: 0.1000\n","Epoch 82/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1890 - accuracy: 0.1000 - val_loss: 0.1876 - val_accuracy: 0.1000\n","Epoch 83/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1867 - accuracy: 0.1000 - val_loss: 0.1854 - val_accuracy: 0.1000\n","Epoch 84/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.1000 - val_loss: 0.1834 - val_accuracy: 0.1000\n","Epoch 85/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1832 - accuracy: 0.1000 - val_loss: 0.1810 - val_accuracy: 0.1000\n","Epoch 86/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.1809 - accuracy: 0.1000 - val_loss: 0.1789 - val_accuracy: 0.1000\n","Epoch 87/100\n","10/10 [==============================] - 0s 8ms/step - loss: 0.1777 - accuracy: 0.1000 - val_loss: 0.1769 - val_accuracy: 0.1000\n","Epoch 88/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.1778 - accuracy: 0.1000 - val_loss: 0.1745 - val_accuracy: 0.1000\n","Epoch 89/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.1000 - val_loss: 0.1725 - val_accuracy: 0.1000\n","Epoch 90/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.1000 - val_loss: 0.1701 - val_accuracy: 0.1000\n","Epoch 91/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.1000 - val_loss: 0.1681 - val_accuracy: 0.1000\n","Epoch 92/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.1000 - val_loss: 0.1662 - val_accuracy: 0.1000\n","Epoch 93/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1664 - accuracy: 0.1000 - val_loss: 0.1641 - val_accuracy: 0.1000\n","Epoch 94/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1633 - accuracy: 0.1000 - val_loss: 0.1619 - val_accuracy: 0.1000\n","Epoch 95/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1613 - accuracy: 0.1000 - val_loss: 0.1597 - val_accuracy: 0.1000\n","Epoch 96/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.1000 - val_loss: 0.1578 - val_accuracy: 0.1000\n","Epoch 97/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1586 - accuracy: 0.1000 - val_loss: 0.1557 - val_accuracy: 0.1000\n","Epoch 98/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.1551 - accuracy: 0.1000 - val_loss: 0.1536 - val_accuracy: 0.1000\n","Epoch 99/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.1000 - val_loss: 0.1518 - val_accuracy: 0.1000\n","Epoch 100/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.1510 - accuracy: 0.1000 - val_loss: 0.1497 - val_accuracy: 0.1000\n","10/10 [==============================] - 0s 2ms/step - loss: 149.7450 - accuracy: 0.0000e+00\n","loss :  149.74502563476562\n","acc :  0.0\n"]}]},{"cell_type":"code","source":["output = model.predict(x_test)\n","print(\"결과물 : \\n\", output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2E0Wd32b366","executionInfo":{"status":"ok","timestamp":1660638020972,"user_tz":-540,"elapsed":13,"user":{"displayName":"김기흥","userId":"07451133083562510396"}},"outputId":"0d359be2-a8d4-47d5-b069-95786c6382fd"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["결과물 : \n"," [[89.32543 ]\n"," [90.201584]\n"," [91.077736]\n"," [91.953896]\n"," [92.83006 ]\n"," [93.706215]\n"," [94.582375]\n"," [95.458534]\n"," [96.334694]\n"," [97.210846]]\n"]}]}]}